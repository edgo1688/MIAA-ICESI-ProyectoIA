{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e57b113e",
   "metadata": {},
   "source": [
    "# Evaluación del modelo Xception para el Tamizaje automatizado de glaucoma con Inteligencia Artificial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7831c50e",
   "metadata": {},
   "source": [
    "# 3. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6ca107",
   "metadata": {},
   "source": [
    "Predicción de Glaucoma con bases públicas ORIGA, REFUGE y G1020.\n",
    "Xception (Extreme Inception) es una arquitectura de red neuronal convolucional profunda propuesta por François Chollet en 2017. Parte de la familia Inception, pero reemplaza los módulos clásicos por convoluciones separables en profundidad (depthwise separable), lo que reduce drásticamente el número de parámetros sin sacrificar capacidad de representación. Gracias a esa eficiencia y a su entrenamiento previo en ImageNet, Xception se adapta muy bien a tareas médicas donde los conjuntos de datos son limitados, como la clasificación de imágenes de fondo de ojo para detectar Glaucoma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce021e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ────────────────────────── Bloque 0 – Librerías y entorno ──────────────────────────\n",
    "import warnings, os, random, cv2, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.layers import (Input, GlobalAveragePooling2D, Dense,\n",
    "                                     Dropout, BatchNormalization)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import (EarlyStopping, ReduceLROnPlateau,\n",
    "                                        ModelCheckpoint)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (confusion_matrix, classification_report,\n",
    "                             precision_score, recall_score, f1_score, roc_auc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0bb30a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # 0=ALL, 1=INFO, 2=WARNING, 3=ERROR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3e61c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GPU detectada: /physical_device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# Configuración reproducible\n",
    "SEED = 42\n",
    "tf.keras.utils.set_random_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Verificación GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"✅ GPU detectada: {gpus[0].name}\")\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  No se pudo habilitar memory growth: {e}\")\n",
    "else:\n",
    "    print(\"⚠️  No hay GPU, trabajaremos en CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44926266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparámetros globales\n",
    "IMG_SIZE   = (299, 299)\n",
    "BATCH      = 16\n",
    "EPOCHS     = 30\n",
    "LR         = 1e-4\n",
    "VAL_SPLIT  = 0.10\n",
    "TEST_SPLIT = 0.10\n",
    "AUTOTUNE   = tf.data.AUTOTUNE\n",
    "WORK_DIR   = r\"G:\\Mi unidad\\Master_MIAA\\1er_Semestre\\5_ProyectoiNN\\MIAA-ICESI-ProyectoIA\\models\"\n",
    "USE_CLAHE  = True          # Activa o desactiva CLAHE\n",
    "CLAHE_CLIP = 2.0           # Parámetro de contraste para CLAHE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832c2f79",
   "metadata": {},
   "source": [
    "## Descripción de las bases de datos:\n",
    "\n",
    "1. ORIGA(-light) contiene 650 imágenes retinianas anotadas por profesionales formados del Instituto de Investigación Ocular de Singapur.\n",
    "\n",
    "    La base de datos está compuesta por un conjunto de imágenes y un archivo en formato CSV que contiene las columnas que se aprecian a continuación:\n",
    "\n",
    "    Las  columnas (Image, CDR, Ecc-Cup, Ecc-Disc)  corresponden a variables explicativas y la última (Glaucoma) corresponde a nuestra variable clasificatoria.\n",
    "\n",
    "    Cada una de estas columnas se explica de la siguiente manera:\n",
    "\n",
    "\n",
    "    - Image: Nombre de archivo de imagen.\n",
    "    - Source: Fuente del dato\n",
    "    - CDR: Cup-to-Disc Ratio. Proporción entre el diámetro del \"cup\" (excavación central) y el disco óptico. Valor clave en la detección de glaucoma..\n",
    "    - Ecc-Cup: Excentricidad de la región de excavación del nervio óptico (cup). Una medida morfológica.\n",
    "    - Ecc-Disc: Excentricidad del disco óptico completo. Ayuda a describir la forma del disco.\n",
    "    - Glaucoma: Variable clasificatoria que identifica el diagnóstico negativo (0) o positivo (1) del glaucoma\n",
    "\n",
    "2. G1020 esta base de datos consta de 1020 imágenes de fondo de ojo en color de alta resolución y proporciona anotaciones de la verdad fundamental para el diagnóstico del glaucoma.\n",
    "\n",
    "    La base de datos está compuesta por un conjunto de imágenes y un archivo en formato CSV en donde se encuentra el label de la variable predictora (Glaucoma).\n",
    "\n",
    "3. REFUGE (Retinal Fundus Glaucoma Challenge) es una base de datos pública creada para fomentar el desarrollo de algoritmos de inteligencia artificial en la detección automática de glaucoma a partir de imágenes de fondo de ojo (retinografías). Contiene 1200 imágenes de fondo de ojo (color fundus images) de alta calidad, provenientes de los centros clínicos Zhongshan Ophthalmic Center (ZOC) y Beijing Tongren Hospital (TR).\n",
    "\n",
    "### Bases de datos públicas utilizadas para detección de Glaucoma\n",
    "\n",
    "| Dataset  | Nº de Imágenes | Resolución | Anotaciones Disponibles | Etiqueta de Glaucoma | Fuente | Acceso |\n",
    "|----------|----------------|------------|--------------------------|----------------------|--------|--------|\n",
    "| **REFUGE** | 1200 | ~2124×2056 px | Segmentación de disco y copa óptica | ✅ | Zhongshan Ophthalmic Center, Beijing Tongren Hospital | [refuge.grand-challenge.org](https://refuge.grand-challenge.org/) |\n",
    "| **ORIGA**  | 650  | 3072×2048 px   | Segmentación + CDR + labels | ✅ | Singapore Eye Research Institute | [Kaggle](https://www.kaggle.com/datasets/arnavjain1/glaucoma-datasets?select=ORIGA) |\n",
    "| **G1020**  | 1020 | 2124×2056 px   | Segmentación + medidas clínicas (CDR, VCDR, etc.) | ✅ | MESSIDOR + anotación médica posterior | [G1020 en Zenodo](https://zenodo.org/record/6333984) |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0422c4ad",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c31542d3",
   "metadata": {},
   "source": [
    "## Carga de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13526efa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_g1020' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ────────────────── Bloque 1 – Lectura / limpieza del DataFrame ──────────────────\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Tus lecturas originales (se asume que ya existen las variables):\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#   df_origa, df_g1020, df_refuge_train\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Aseguramos columnas uniformes\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m df_g1020   = \u001b[43mdf_g1020\u001b[49m.rename(columns={\u001b[33m'\u001b[39m\u001b[33mimageID\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mImage\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mbinaryLabels\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mGlaucoma\u001b[39m\u001b[33m'\u001b[39m})\n\u001b[32m      7\u001b[39m df_origa   = df_origa.rename(columns={\u001b[33m'\u001b[39m\u001b[33mLabel\u001b[39m\u001b[33m'\u001b[39m    : \u001b[33m'\u001b[39m\u001b[33mGlaucoma\u001b[39m\u001b[33m'\u001b[39m})\n\u001b[32m      8\u001b[39m df_refuge_train = df_refuge_train.rename(columns={\u001b[33m'\u001b[39m\u001b[33mImgName\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mImage\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mLabel\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mGlaucoma\u001b[39m\u001b[33m'\u001b[39m})\n",
      "\u001b[31mNameError\u001b[39m: name 'df_g1020' is not defined"
     ]
    }
   ],
   "source": [
    "# ────────────────── Bloque 1 – Lectura / limpieza del DataFrame ──────────────────\n",
    "# Tus lecturas originales (se asume que ya existen las variables):\n",
    "#   df_origa, df_g1020, df_refuge_train\n",
    "\n",
    "# Aseguramos columnas uniformes\n",
    "df_g1020   = df_g1020.rename(columns={'imageID': 'Image', 'binaryLabels': 'Glaucoma'})\n",
    "df_origa   = df_origa.rename(columns={'Label'    : 'Glaucoma'})\n",
    "df_refuge_train = df_refuge_train.rename(columns={'ImgName': 'Image', 'Label': 'Glaucoma'})\n",
    "\n",
    "# Fuente\n",
    "df_origa['Source']        = 'ORIGA'\n",
    "df_g1020['Source']        = 'G1020'\n",
    "df_refuge_train['Source'] = 'REFUGE'\n",
    "\n",
    "# Unificamos\n",
    "df_glaucoma = pd.concat(\n",
    "    [df_origa[['Image','Source','Glaucoma']],\n",
    "     df_g1020[['Image','Source','Glaucoma']],\n",
    "     df_refuge_train[['Image','Source','Glaucoma']]],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Añadimos columna Path\n",
    "ROOT = r\"G:\\Mi unidad\\Master_MIAA\\1er_Semestre\\5_ProyectoiNN\\MIAA-ICESI-ProyectoIA\\datos\"\n",
    "map_roots = {\n",
    "    'ORIGA' : os.path.join(ROOT, 'ORIGA', 'Images'),\n",
    "    'G1020' : os.path.join(ROOT, 'G1020', 'Images'),\n",
    "    'REFUGE': os.path.join(ROOT, 'REFUGE', 'train', 'Images'),\n",
    "}\n",
    "\n",
    "def build_path(row):\n",
    "    return os.path.join(map_roots.get(row['Source'], ''), row['Image'])\n",
    "\n",
    "df_glaucoma['Path'] = df_glaucoma.apply(build_path, axis=1)\n",
    "\n",
    "# Chequeo rápido\n",
    "display(df_glaucoma.head())\n",
    "print(\"Distribución de clases:\\n\", df_glaucoma['Glaucoma'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99d09cd",
   "metadata": {},
   "source": [
    "Bloque 2 – Split estratificado y pesos de clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac65b132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ────────────────────── Bloque 2 – Train / Val / Test Split ──────────────────────\n",
    "train_df, temp_df = train_test_split(\n",
    "    df_glaucoma,\n",
    "    test_size=VAL_SPLIT + TEST_SPLIT,\n",
    "    stratify=df_glaucoma['Glaucoma'],\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size = TEST_SPLIT / (VAL_SPLIT + TEST_SPLIT),\n",
    "    stratify  = temp_df['Glaucoma'],\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)}\")\n",
    "\n",
    "# Pesos de clase para mitigar el desequilibrio\n",
    "neg, pos = df_glaucoma['Glaucoma'].value_counts().sort_index().tolist()\n",
    "total = neg + pos\n",
    "class_weight = {\n",
    "    0: total / (2 * neg),\n",
    "    1: total / (2 * pos)\n",
    "}\n",
    "print(\"Pesos de clase:\", class_weight)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af7b987",
   "metadata": {},
   "source": [
    "Bloque 3 – Data pipeline con tf.data y (opcional) CLAHE + augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90553cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────── Bloque 3 ─────────────\n",
    "def clahe_np(img, clip=CLAHE_CLIP):\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l)\n",
    "    merged = cv2.merge((cl, a, b))\n",
    "    rgb = cv2.cvtColor(merged, cv2.COLOR_LAB2RGB)\n",
    "    return rgb\n",
    "\n",
    "def process_path(path, label):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)  # [0,1]\n",
    "\n",
    "    if USE_CLAHE:\n",
    "        img = tf.numpy_function(clahe_np, [tf.cast(img * 255.0, tf.uint8), CLAHE_CLIP], tf.uint8)\n",
    "        img.set_shape([None, None, 3])            # ← recupera dims perdidas\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    return img, tf.cast(label, tf.float32)\n",
    "\n",
    "def random_zoom(img, zoom_range=(0.9, 1.1)):\n",
    "    zoom = tf.random.uniform([], zoom_range[0], zoom_range[1])\n",
    "    new_size = tf.cast(tf.cast(IMG_SIZE, tf.float32) * zoom, tf.int32)\n",
    "    img = tf.image.resize_with_crop_or_pad(img, new_size[0], new_size[1])\n",
    "    return tf.image.resize(img, IMG_SIZE)\n",
    "\n",
    "def augment(img, label):\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    img = tf.image.random_brightness(img, 0.15)\n",
    "    img = random_zoom(img)                       # ← zoom casero\n",
    "    return img, label\n",
    "\n",
    "train_ds = build_dataset(train_df, training=True)\n",
    "val_ds   = build_dataset(val_df, training=False)\n",
    "test_ds  = build_dataset(test_df, training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5513e86",
   "metadata": {},
   "source": [
    "Bloque 4 – Definición del modelo Xception + top layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9167dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────────────────── Bloque 4 – Arquitectura y compilación ─────────────────────────\n",
    "inputs = Input(shape=(*IMG_SIZE, 3))\n",
    "base   = Xception(weights='imagenet', include_top=False, input_tensor=inputs)\n",
    "base.trainable = False  # Transfer learning congelado\n",
    "\n",
    "x = GlobalAveragePooling2D()(base.output)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy',\n",
    "             tf.keras.metrics.AUC(name='auc'),\n",
    "             tf.keras.metrics.Precision(name='precision'),\n",
    "             tf.keras.metrics.Recall(name='recall')]\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45db610e",
   "metadata": {},
   "source": [
    "Bloque 5 – Callbacks y entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deb80a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────── Bloque 5 – Callbacks y entrenamiento ────────────────────────\n",
    "os.makedirs(WORK_DIR, exist_ok=True)\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_auc', patience=5, mode='max', restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_auc', factor=0.3, patience=3, mode='max', min_lr=1e-7),\n",
    "    ModelCheckpoint(\n",
    "        filepath=os.path.join(WORK_DIR, 'xception_glaucoma_best.h5'),\n",
    "        monitor='val_auc', mode='max', save_best_only=True, verbose=1)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weight,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f30480a",
   "metadata": {},
   "source": [
    "Bloque 6 – Curvas de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a9afd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ────────────────────────── Bloque 6 – Curvas ACC / AUC ──────────────────────────\n",
    "def plot_metric(metric_name):\n",
    "    plt.figure()\n",
    "    plt.plot(history.history[metric_name], label=f'Train {metric_name}')\n",
    "    plt.plot(history.history[f'val_{metric_name}'], label=f'Val {metric_name}')\n",
    "    plt.title(metric_name.upper())\n",
    "    plt.xlabel('Epochs'); plt.ylabel(metric_name); plt.legend(); plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "for m in ['accuracy', 'auc', 'precision', 'recall', 'loss']:\n",
    "    plot_metric(m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ea6566",
   "metadata": {},
   "source": [
    "Bloque 7 – Evaluación en el set de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960e0ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ────────────────────────── Bloque 7 – Evaluación final ──────────────────────────\n",
    "# 1. Métricas directas\n",
    "test_loss, test_acc, test_auc, test_prec, test_rec = model.evaluate(test_ds, verbose=0)\n",
    "test_f1 = 2 * (test_prec * test_rec) / (test_prec + test_rec + 1e-7)\n",
    "print(f\"\\nTest  | Acc: {test_acc:.3f}  AUC: {test_auc:.3f}  \"\n",
    "      f\"Prec: {test_prec:.3f}  Rec: {test_rec:.3f}  F1: {test_f1:.3f}\")\n",
    "\n",
    "# 2. Confusion matrix y reporte completo\n",
    "y_true = np.concatenate([y for _, y in test_ds], axis=0)\n",
    "y_pred_prob = model.predict(test_ds).ravel()\n",
    "y_pred = (y_pred_prob >= 0.5).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"\\nMatriz de confusión:\\n\", cm)\n",
    "\n",
    "print(\"\\nClasificación detallada:\\n\",\n",
    "      classification_report(y_true, y_pred, digits=3))\n",
    "\n",
    "# ROC-AUC (sklearn)\n",
    "print(\"ROC-AUC (sklearn):\", roc_auc_score(y_true, y_pred_prob).round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28308ebf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
