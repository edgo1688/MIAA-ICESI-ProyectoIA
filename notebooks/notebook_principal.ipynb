{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e57b113e",
   "metadata": {},
   "source": [
    "# Tamizaje automatizado de glaucoma con inteligencia artificial\n",
    "\n",
    "### 1. Entendimiento del Negocio\n",
    "- 1.1 Declaración del problema\n",
    "- 1.2 Árbol de problemas\n",
    "- 1.3 Objetivo SMART\n",
    "- 1.4 Revisión de la literatura\n",
    "\n",
    "### 2. Entendimiento de los Datos\n",
    "- 2.1 Visión General de los Datos Disponibles\n",
    "- 2.2 Diccionario de Datos\n",
    "- 2.3 Análisis Exploratorio de Datos (EDA) ????\n",
    "  - 2.3.1 Análisis Univariado con visualización ????\n",
    "  - 2.3.2 Análisis Multivariado: Variables Relevantes ????\n",
    "  - 2.3.3 Valores Atípicos y Valores Faltantes ????\n",
    "  - 2.3.4 Principales Hallazgos del EDA ????\n",
    "\n",
    "### 3. Preparación de los Datos\n",
    "- 3.1 Limpieza de Datos e Imputación \n",
    "- 3.2 Ingeniería de Características\n",
    "- Preprocesamiento de imágenes (Redimensionamiento, Normalización, Conversión a escala de grises o color (según convenga))\n",
    "- Aumento de datos (Data Augmentation): Rotaciones, giros, zooms, flips y Justificación de uso\n",
    "- 3.3 Estrategia de División de Datos (Entrenamiento/Test/Validación)\n",
    "\n",
    "### 4. Modelado\n",
    "- 4.1 Desarrollo del Modelo\n",
    "Diseño del modelo CNN\n",
    "Explicación de arquitectura (puede ser una CNN desde cero o transfer learning: VGG, ResNet, etc.)\n",
    "Justificación de capas, activaciones, etc.\n",
    "- Compilación y entrenamiento del modelo\n",
    "Función de pérdida, optimizador y métricas\n",
    "Gráfica de pérdida y accuracy por época\n",
    "- 4.2 Resultados y Limitaciones del Modelo\n",
    "- 4.3 Validación cruzada y Métricas\n",
    "Accuracy, precision, recall, F1-score\n",
    "Matriz de confusión\n",
    "Curva ROC y AUC\n",
    "Análisis de errores\n",
    "\n",
    "### 5. Evaluación\n",
    "- 5.2 Resultados obtenidos y Comparación de modelos\n",
    "- 5.3 Aplicaciones prácticas\n",
    "- 5.4 Limitaciones y trabajos futuros\n",
    "- 5.5 Anexos (Opcional)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310105fb",
   "metadata": {},
   "source": [
    "# 1. Entendimiento del Negocio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b017baa4",
   "metadata": {},
   "source": [
    "## 1.1 Declaración del problema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c50da3",
   "metadata": {},
   "source": [
    "El glaucoma es una neuropatía óptica crónica y una de las principales causas de ceguera irreversible a nivel mundial​. Se estima que afecta a más de 76 millones de personas para 2020, con proyecciones que superan los 110 millones en 2040 [1]​. Este impacto conlleva costos económicos sustanciales: por ejemplo, en EE.UU. el tratamiento de ~2 millones de pacientes con glaucoma implica costos directos anuales de ~$2.9 mil millones​ [2]. Gran parte de esta pérdida de visión es evitable mediante diagnóstico y tratamiento oportunos; sin embargo, el tamizaje masivo de glaucoma presenta varios desafíos. Existe escasez de oftalmólogos para cubrir a poblaciones envejecidas y rurales, y las evaluaciones clínicas son lentas y subjetivas. La detección tradicional requiere exámenes especializados (ej. tonometría, campimetría visual) y equipos costosos como OCT (tomografía de coherencia óptica), poco viables para despistajes poblacionales extensivos por su tiempo y costo. Además, hay variabilidad diagnóstica incluso entre expertos, especialmente en etapas tempranas donde los hallazgos (como la relación copa/disco) pueden ser sutiles [3].\n",
    "\n",
    "El problema central es cómo realizar un tamizaje automatizado, rápido y preciso del glaucoma usando imágenes de fondo de ojo, superando las limitaciones actuales. Los stakeholders clave incluyen: pacientes (quienes se benefician de la detección precoz para prevenir la ceguera), aseguradoras/EPS (que buscan reducir costos de tratamientos tardíos), hospitales y clínicas (que podrían agilizar flujos de trabajo de oftalmología), startups y fabricantes de dispositivos (desarrollando cámaras portátiles y software de IA para detección ocular), y entes reguladores (FDA, EMA, Invima) que exigen eficacia y seguridad antes de aprobar estas herramientas.\n",
    "\n",
    "Desde la perspectiva del negocio, se han definido restricciones y criterios de éxito mínimos: la herramienta de IA debe alcanzar una precisión clínica aceptable, típicamente sensibilidad ≥ 0.85 y especificidad ≥ 0.80 (umbral mínimo recomendado para tamizaje poblacional)​ [4]. Es fundamental la explicabilidad del modelo – es decir, que provea salidas interpretables (ej. mapa de calor sobre el disco óptico) para generar confianza en médicos y cumplir requerimientos regulatorios. Se deben mitigar riesgos éticos, como sesgos que disminuyan rendimiento en ciertos grupos (p. ej., sobre diagnóstico en etnias específicas) o fallos de privacidad (asegurando anonimización de las imágenes). Además, el sistema debe ser eficiente: inferencia en <1 segundo por imagen y costo por examen <USD $1, para que el tamizaje a gran escala sea viable en entornos de bajos recursos.\n",
    "\n",
    "El enfoque del proyecto es global en lugar de regional: el modelo se entrenará con miras a aplicarse en diversas poblaciones y países, ya que se contará con bases de datos de diferentes latitudes. Esto conlleva retos de generalización: las características demográficas (edad, raza) influyen en la apariencia del fondo de ojo (por ejemplo, diferencias en pigmentación retiniana o tamaño del disco óptico por etnia). Asimismo, existe variabilidad técnica entre dispositivos – distintas cámaras retinianas producen resoluciones y campos de visión heterogéneos. Un algoritmo global debe manejar estos sesgos y variaciones, evitando un desempeño inferior en ciertas regiones. En suma, el problema requiere una solución de IA robusta, explicable y equitativa para el tamizaje universal de glaucoma, optimizando la detección temprana y aliviando la carga asistencial.\n",
    "\n",
    "**REFERENCIAS**\n",
    "\n",
    "[1]  X. Huang, M. R. Islam, S. Akter, F. Ahmed, E. Kazami, H. A. Serhan, A. Abd-alrazaq, and S. Yousefi, “Artificial intelligence in glaucoma: opportunities, challenges, and future directions,” BioMed. Eng. OnLine, vol. 22, art. no. 126, Dec. 2023. [Online]. Available: https://biomedical-engineering-online.biomedcentral.com/articles/10.1186/s12938-023-01187-8.\n",
    "\n",
    "[2] Y. C. Tham, X. Li, T. Y. Wong, H. A. Quigley, et al., “Global prevalence of glaucoma and projections of glaucoma burden through 2040: a systematic review and meta-analysis,” Ophthalmology, vol. 121, no. 11, pp. 2081–2090, 2014. [Online]. Available: https://pubmed.ncbi.nlm.nih.gov/24974815/\n",
    "\n",
    "[3] P. P. Lee, K. G. Walt, and S. L. Wilson, “An assessment of the health and economic burdens of glaucoma,” Archives of Ophthalmology, vol. 129, no. 1, pp. 1–7, 2011. [Online]. Available: https://pmc.ncbi.nlm.nih.gov/articles/PMC3206636/\n",
    "\n",
    "[4] R. Hemelings, B. Elen, A. K. Schuster, et al., “A generalizable deep-learning regression model for automated glaucoma screening from fundus images,” npj Digital Medicine, vol. 6, art. 112, Jun. 2023. [Online]. Available: https://www.nature.com/articles/s41746-023-00857-0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8db0023",
   "metadata": {},
   "source": [
    "## 1.2 Árbol de problemas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c775b7",
   "metadata": {},
   "source": [
    "<img src=\"./resources/glaucoma-problems-tree.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e1c82d",
   "metadata": {},
   "source": [
    "## 1.3 Objetivo SMART"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325b8955",
   "metadata": {},
   "source": [
    "Desarrollar e implementar, para junio de 2025, un sistema automatizado de detección de glaucoma a partir de fotografías de fondo de ojo. El modelo deberá identificar ojos glaucomatosos con al menos un 85% de sensibilidad y un 80% de especificidad, de acuerdo con su desempeño en un conjunto de prueba multicéntrico internacional. Para alcanzar esta meta, se empleará un modelo de deep learning optimizado que justifique cada predicción de manera interpretable. Este objetivo es clínicamente relevante, ya que una herramienta de tamizaje precisa y rápida puede ampliar la detección temprana del glaucoma en comunidades con escasez de especialistas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae79bb9",
   "metadata": {},
   "source": [
    "## 1.4 Revisión de la literatura"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a299929f",
   "metadata": {},
   "source": [
    "#### **Hallazgos clave de estudios recientes (2019–2025).**\n",
    " \n",
    "La aplicación de inteligencia artificial al diagnóstico de glaucoma ha avanzado notablemente en los últimos años (Li et al., 2024). Diversos enfoques han sido investigados, desde algoritmos de aprendizaje profundo hasta técnicas clásicas de visión por computador. Por ejemplo, López-Gálvez et al. (2023) exploraron un **método tradicional basado en análisis de texturas para detectar lesiones retinianas** [1]. Empleando segmentación semiautomática y verificación de regiones, lograron identificar exudados duros en imágenes de fondo de ojo con sensibilidad 0.92–0.98 y especificidad 0.90–0.98 en varios conjuntos de datos​. Si bien este estudio se enfoca en retinopatía diabética (no en glaucoma), ilustra que las técnicas de procesamiento de imagen bien diseñadas (filtro de mediana, detección de bordes, eliminación del disco óptico, etc.) pueden alcanzar alta precisión sin redes neuronales profundas. \n",
    "\n",
    "En contraste, **los métodos basados en deep learning dominan la literatura reciente de glaucoma**. Díaz-Pinto et al. (2019) [2] emplearon cinco arquitecturas CNN pre-entrenadas (VGG16, InceptionV3, ResNet50, Xception, etc.) para clasificación binaria glaucoma/normal en 5 bases de datos públicas (N=1707 imágenes)​. Obtuvieron resultados sobresalientes: el mejor modelo (Xception) rindió AUC ≈0.96, sensibilidad ≈0.93 y especificidad ≈0.86 promediadas​. Además, liberaron una nueva base de 705 imágenes (ACRIMA) con 396 casos de glaucoma, ampliando el mayor conjunto público disponible​. Este trabajo confirmó que la transferencia de aprendizaje desde ImageNet proporciona representaciones robustas en retina, superando enfoques previos con extracción manual de características. De hecho, métodos tradicionales como SVM con descriptores HOG o transformadas wavelet lograban desempeños moderados (ej., accuracies ~80%​), mientras que las CNN aprendieron directamente patrones sutiles del nervio óptico con mayor discriminación.\n",
    "\n",
    "Un **desafío común identificado es la generalización multisitio**. Modelos entrenados en un único centro a menudo ven mermado su desempeño al probarse en datos externos debido a shift de distribución (diferentes poblaciones, prevalencias y dispositivos)​. Hemelings et al. (2023) [3] abordaron este problema integrando 13 fuentes de datos de todo el mundo, incluyendo dos cohortes poblacionales grandes (Blue Mountains Eye Study en Australia y Gutenberg Health Study en Alemania) junto con 11 datasets públicos de glaucoma​. Estandarizaron todas las imágenes a un campo de 30° centrado en el disco óptico para reducir variaciones técnicas​. Entrenaron un modelo de regresión (G-RISK) para estimar la probabilidad de glaucoma (en lugar de solo clasificación binaria), logrando desempeños impresionantes en detección de casos referibles: AUC = 0.976 y 0.984 en las cohortes de población, con sensibilidades ~87–90% a especificidad fija de 95%​. En 11 conjuntos externos adicionales, el AUC osciló entre 0.85 y 0.99​, confirmando la robustez del modelo en entornos desafiantes. Este estudio destaca la importancia de datasets diversos y de preprocesamiento consistente (alinear imágenes al disco) para un enfoque global. \n",
    "\n",
    "De manera complementaria, Li et al. (2022) [4] desarrollaron un **sistema de deep learning capaz de predecir tanto la incidencia de glaucoma en pacientes inicialmente sanos, como la progresión en pacientes ya diagnosticados**, a partir de fotografías de retina. Entrenado con miles de imágenes de múltiples centros en China, su algoritmo alcanzó AUROC ≈0.90 en la predicción a 4 años de nuevos casos de glaucoma, manteniendo AUROC ~0.88–0.89 en dos conjuntos de prueba externos​. Para progresión de glaucoma (deterioro del campo visual), también logró alta exactitud. Un hallazgo importante es que el modelo no mostró diferencias significativas de rendimiento al estratificar por edad o sexo de los pacientes​, lo cual sugiere que el algoritmo supo evitar ciertos sesgos demográficos y podría ser aplicado consistentemente en subpoblaciones diversas. Esto es crítico para la equidad del tamizaje.\n",
    "\n",
    "La literatura reciente también ha explorado **arquitecturas novedosas y combinaciones de modalidades**. Sharma et al. (2025) [5] propusieron un enfoque híbrido multi-modelo llamado AI-GS, que integra 6 sub-modelos livianos enfocados en distintos biomarcadores de glaucoma (segmentación de la copa y disco óptico, detección de hemorragias discales, defectos de capa de fibras nerviosas, etc.)​. Cada sub-modelo (<20 MB) analiza la imagen de fondo de ojo para una característica específica; luego sus salidas se fusionan en una red plenamente conectada que estima la probabilidad final de glaucoma​. En un set de prueba interno, AI-GS alcanzó sensibilidad = 93,5% a 95% de especificidad​, superando claramente el umbral clínico. En pruebas de campo real (pacientes de clínica, con variabilidad no controlada), reportaron que un modelo CNN estándar sufría una caída de sensibilidad a ~56% manteniendo ~94% especificidad, mientras que la red completa AI-GS mantuvo ≈80.5% de sensibilidad con ~91% especificidad​. Esto demuestra que combinar múltiples detectores especializados mejora la sensibilidad en datos del mundo real, detectando cambios sutiles que un único clasificador podía pasar por alto​. No obstante, también refleja la brecha que suele haber entre la evaluación controlada y el desempeño clínico real, subrayando la importancia de validar con datos prospectivos. \n",
    "\n",
    "En otra línea, Díaz-Pinto et al. (2019) [2] y otros autores resaltan la **necesidad de imágenes de alta calidad para un diagnóstico fiable**. Imágenes borrosas o con mala iluminación pueden inducir errores; por ello, se han propuesto modelos auxiliares que filtren automáticamente imágenes no aptas. Por ejemplo, una red de clasificación de calidad puede descartar fotos desenfocadas antes del análisis principal (Ran et al., 2022) [6]. Asimismo, varios trabajos incorporan medidas clínicas explícitas: segmentar el disco y la copa óptica para calcular la relación copa/disco (CDR) e incluirla como característica en la decisión. Este enfoque híbrido combina la naturaleza data-driven de las CNN con conocimiento clínico previo – CDR elevada es un indicador tradicional de glaucoma. Estudios han demostrado que agregar CDR u otros rasgos (excavación, hemorragias peripapilares) mejora la interpretabilidad e incluso la precisión del modelo (Shankaranarayana et al., 2020) [7]. \n",
    "\n",
    "En cuanto a plataformas emergentes, se investiga la aplicabilidad en dispositivos móviles: por ejemplo, algoritmos optimizados para ejecutarse en smartphones acoplados a lentes de bajo costo, lo que permitiría tamizajes en campo. Un ejemplo es el uso de Vision Transformers y métodos compactos en aplicaciones de tele-oftalmología móvil (Li et al., 2024; Xu et al., 2023) [8], aunque aún es un área en desarrollo.\n",
    "\n",
    "#### **Mejores prácticas y vacíos identificados**. \n",
    "\n",
    "De la revisión de estos artículos se desprenden varias recomendaciones técnicas relevantes para nuestro proyecto. Primero, el **manejo de la clase minoritaria (ojos glaucomatosos) es crucial**: en poblaciones generales la prevalencia de glaucoma puede ser <5%, de modo que entrenar un modelo sin técnicas de balanceo puede sesgarlo a predecir “sano” la mayoría de veces. Los investigadores han utilizado enfoques de oversampling (replicar o sintetizar imágenes de glaucoma) y cost-sensitive learning (ponderar más los errores en glaucomatosos). Por ejemplo, algunos grupos aplicaron focal loss o ajustaron manualmente el peso de falsos negativos para priorizar la sensibilidad (Li et al., 2024) [8]. Esto coincide con la prioridad clínica de minimizar falsos negativos – es preferible marcar un caso como sospechoso (aunque luego se descarte con exámenes confirmatorios) que perder un glaucoma real por no detectarlo. Segundo, se ha validado la **utilidad del transfer learning**: la mayoría de estudios (Díaz-Pinto 2019, Hemelings 2023, etc.) iniciaron entrenando sus CNN con pesos de ImageNet​, dado el limitado tamaño de datasets médicos. Esto aceleró la convergencia y permitió que modelos complejos rindieran bien con cientos o pocos miles de imágenes. Tercero, las **técnicas de data augmentation se consideran indispensables**. Todos los trabajos analizados aplicaron transformaciones aleatorias a las imágenes de entrenamiento (giros, espejado horizontal, variaciones de brillo/contraste). Algunas publicaciones implementaron augmentations más sofisticadas: deformaciones elásticas simulando distorsiones oculares, recortes aleatorios centrados en el nervio, e incluso redes generativas (GANs) para crear imágenes sintéticas de discos excavados. López-Gálvez et al. (2023) [1] mencionan que su método clásico evitó depender de equalización de iluminación o segmentación vascular previa, lo que simplifica la generalización​; sin embargo, en modelos de deep learning sí se sugiere normalizar la coloración y eliminar artefactos (reflejos) en pre-procesamiento para reducir la variabilidad no informativa. \n",
    "\n",
    "Otro aspecto crítico es la **interpretabilidad**. Dado que las autoridades regulatorias ahora exigen justificar las decisiones de los algoritmos médicos, muchos estudios integran métodos de explicación. Los más comunes son Grad-CAM (mapas de activación vinculados a la predicción) y LIME, que señalan regiones del fondo de ojo que contribuyen al diagnóstico (usualmente el área del disco óptico y la capa de fibras nerviosas). Por ejemplo, Li et al. (2024) [8] en su revisión enfatizan que la transparencia es clave para la adopción clínica, y proponen que un enfoque ideal podría involucrar un sistema híbrido, donde la IA no solo indique “glaucoma: sí/no” sino que provea medidas cuantitativas tradicionales (como CDR) y visualizaciones comprensibles (p. ej., destacar una hemorragia discal detectada).\n",
    "\n",
    "Finalmente, permanecen vacíos importantes en la literatura. Pocos trabajos han validado sus algoritmos en población latinoamericana o africana, representando una brecha de equidad. Asimismo, la mayoría de estudios utilizan solo imágenes de fondo de ojo estáticas; integrar datos multimodales (OCT, campos visuales, presión intraocular) podría mejorar la sensibilidad en casos tempranos donde la foto de retina por sí sola es insuficiente​. También se señala que la heterogeneidad de criterios diagnósticos complica la comparación entre modelos – distintos datasets usan definiciones de glaucoma diferentes (p. ej., basado en CDR vs. basado en campos visuales)​. Esto sugiere la necesidad de estándares unificados y quizá entrenar modelos para estudiar severidad y no solo detección binaria. \n",
    "\n",
    "En resumen, las investigaciones de 2019-2025 demuestran que la IA puede lograr desempeño cercano (incluso superior) al de especialistas en la detección de glaucoma (sensibilidades típicamente 90%+​) [9], pero para trasladar esta eficacia a escenarios globales reales deben atenderse la generalización, interpretabilidad y sesgos, orientando así la propuesta de nuestro proyecto.\n",
    "\n",
    "En función de lo revisado, identificamos áreas donde este proyecto puede aportar valor:\n",
    "\n",
    "- Validación en Latinoamérica: Actualmente falta evidencia de desempeño de algoritmos de glaucoma en poblaciones latinoamericanas. Nuestro proyecto puede liderar estudios de validación externa en Colombia, probando la herramienta en etnias y condiciones locales poco representadas, y ajustando el modelo para cubrir esas diferencias (p. ej., prevalencia de pseudoexfoliación, características genéticas particulares). Esto aumentará la confianza de adoptabilidad regional.\n",
    "\n",
    "- Mejora en interpretabilidad y confianza del usuario: Aunque muchos estudios mencionan Grad-CAM, pocos han evaluado sistemáticamente cómo usan los clínicos esas explicaciones. El proyecto puede innovar presentando las salidas de IA de forma intuitiva y validándolas con oftalmólogos en un entorno simulado. Esto cerraría la brecha entre un algoritmo con buen desempeño y su aceptación en práctica real, ofreciendo un ejemplo de IA explicable centrada en el usuario.\n",
    "\n",
    "**REFERENCIAS**\n",
    "\n",
    "[1] M. I. López-Gálvez, R. Romera-Oraa, M. García, J. Oraa-Pérez, and R. Hornero, “Exudate identification in retinal fundus images using precise textural verifications” Sci. Rep., vol. 13, art. 2824, 2023.\n",
    "\n",
    "[2] A. Díaz-Pinto, S. Morales, V. Naranjo, T. Köhler, J. M. Mossi, and A. Navea, “CNNs for automatic glaucoma assessment using fundus images: an extensive validation,” Biomed. Eng. Online, vol. 18, art. 29, 2019.\n",
    "\n",
    "[3] R. Hemelings, B. Elen, A. K. Schuster, et al., “A generalizable deep-learning regression model for automated glaucoma screening from fundus images” npj Digit. Med., vol. 6, art. 112, 2023.\n",
    "\n",
    "[4] F. Li, Y. Su, F. Lin, et al., “A deep-learning system predicts glaucoma incidence and progression using retinal photographs” J. Clin. Invest., vol. 132, no. 11, e157968, 2022.\n",
    "\n",
    "[5] P. Sharma, N. Takahashi, T. Ninomiya, et al., “A hybrid multi-model AI approach for glaucoma screening using fundus images” npj Digit. Med., vol. 8, art. 130, 2025.\n",
    "\n",
    "[6] A. Ran, Y. Li, X. Chen, and L. Zhao, “Deep-learning-based quality assessment of fundus images for automated glaucoma detection” Eye, vol. 36, pp. 343–351, 2022.\n",
    "\n",
    "[7] S. Shankaranarayana, P. Sridhar, A. Anand, and J. Venkatesh, “Automated diagnosis of glaucoma using deep learning and optic-disc-based features” Comput. Biol. Med., vol. 127, art. 104048, 2020.\n",
    "\n",
    "[8] Y. Li, J. Jin, L. Liang, K. Xu, W. Zhou, and Y. Li, “Artificial intelligence and glaucoma: a lucid and comprehensive review” Front. Med., vol. 11, art. 1423813, 2024.\n",
    "\n",
    "[9] S. C. Shen, Y. S. Lee, P. W. Chen, et al., “Deep learning in glaucoma detection and progression prediction: a systematic review and meta-analysis,” Diagnostics, vol. 13, no. 4, art. 783, 2025."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6a4cb4",
   "metadata": {},
   "source": [
    "# 2. Entendimiento de Los Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6352f668",
   "metadata": {},
   "source": [
    "## 2.1 Visión General de los Datos Disponibles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c657f24b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4633fbcd",
   "metadata": {},
   "source": [
    "## 2.2 Diccionario de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69db49bf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f4d61b5",
   "metadata": {},
   "source": [
    "## 2.3 Análisis Exploratorio de Datos (EDA)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
